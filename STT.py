#!/usr/bin/env python3
"""
Whisper STT ìµœì¢… í†µí•© ë²„ì „ (í¬ë¡œìŠ¤ í”Œë«í¼)
- ë©”ëª¨ë¦¬ ì•ˆì „ì„± ìµœì í™”
- ì˜¤ë””ì˜¤ íŒŒì¼ ìë™ íƒì§€  
- ëª¨ë¸ë³„ ì•ˆì •ì„± ì²´í¬
- macOS + Windows ìµœì í™”
- ì‹¤ì‹œê°„ STT ì§€ì›
- ì²­í¬ ê¸°ë°˜ ì²˜ë¦¬
- ì¢…í•©ì  ì—ëŸ¬ ì²˜ë¦¬
"""

import whisper
import torch
import gc
import os
import argparse
import glob
import signal
import sys
import platform
from contextlib import contextmanager

# ========================================
# ì•ˆì „ì„± ì„¤ì •
# ========================================

# ì•ˆì „í•œ ëª¨ë¸ vs ìœ„í—˜í•œ ëª¨ë¸
SAFE_MODELS = ['tiny', 'base', 'small', 'medium']
RISKY_MODELS = ['large-v1', 'large-v2', 'large-v3']

# ëª¨ë¸ë³„ ìƒì„¸ ì •ë³´
MODEL_INFO = {
    'tiny': {'size_mb': 39, 'accuracy': 'ë‚®ìŒ', 'speed': 'ë§¤ìš° ë¹ ë¦„', 'memory': '100MB', 'stable': True},
    'base': {'size_mb': 144, 'accuracy': 'ë³´í†µ', 'speed': 'ë¹ ë¦„', 'memory': '300MB', 'stable': True},
    'small': {'size_mb': 488, 'accuracy': 'ì¢‹ìŒ', 'speed': 'ë³´í†µ', 'memory': '800MB', 'stable': True},
    'medium': {'size_mb': 1550, 'accuracy': 'ë§¤ìš° ì¢‹ìŒ', 'speed': 'ëŠë¦¼', 'memory': '2GB', 'stable': True},
    'large-v1': {'size_mb': 2950, 'accuracy': 'ìµœê³ ', 'speed': 'ë§¤ìš° ëŠë¦¼', 'memory': '3.5GB', 'stable': False},
    'large-v2': {'size_mb': 2950, 'accuracy': 'ìµœê³ ', 'speed': 'ë§¤ìš° ëŠë¦¼', 'memory': '3.5GB', 'stable': False},
    'large-v3': {'size_mb': 2950, 'accuracy': 'ìµœê³ ', 'speed': 'ë§¤ìš° ëŠë¦¼', 'memory': '3.5GB', 'stable': False},
}

# ========================================
# ë©”ëª¨ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤
# ========================================

class WhisperMemoryManager:
    """Whisper ì „ìš© ë©”ëª¨ë¦¬ ê´€ë¦¬"""
    
    def __init__(self):
        self.setup_environment()
        
    def setup_environment(self):
        """í¬ë¡œìŠ¤ í”Œë«í¼ í™˜ê²½ ìµœì í™” (macOS + Windows)"""
        
        # í”Œë«í¼ ê°ì§€
        current_platform = platform.system().lower()
        is_apple_silicon = platform.machine() == 'arm64'
        is_windows = current_platform == 'windows'
        is_macos = current_platform == 'darwin'
        
        # ê³µí†µ í™˜ê²½ ì„¤ì • (ëª¨ë“  í”Œë«í¼)
        common_env = {
            'OMP_NUM_THREADS': '1',
            'MKL_NUM_THREADS': '1', 
            'NUMEXPR_NUM_THREADS': '1',
            'TOKENIZERS_PARALLELISM': 'false',
            'PYTORCH_ENABLE_MPS_FALLBACK': '1',
            'OMP_MAX_ACTIVE_LEVELS': '1',
            'OMP_NESTED': 'FALSE',
        }
        
        # macOS ì „ìš© ì„¤ì •
        if is_macos:
            macos_env = {
                'VECLIB_MAXIMUM_THREADS': '1',     # Apple Accelerate ì œí•œ
                'OPENBLAS_NUM_THREADS': '1',       # OpenBLAS ì œí•œ
                'MKL_THREADING_LAYER': 'SEQUENTIAL',
            }
            common_env.update(macos_env)
            
            # Apple Silicon ì¶”ê°€ ìµœì í™”
            if is_apple_silicon:
                common_env.update({
                    'MALLOC_CHECK_': '0',
                    'PYTHONMALLOC': 'malloc',
                })
        
        # Windows ì „ìš© ì„¤ì •  
        elif is_windows:
            windows_env = {
                'MKL_THREADING_LAYER': 'INTEL',    # Windowsì—ì„œ Intel ë ˆì´ì–´
                'CUDA_VISIBLE_DEVICES': '',        # GPU ë¹„í™œì„±í™” (ì•ˆì •ì„±)
            }
            common_env.update(windows_env)
        
        # í™˜ê²½ ë³€ìˆ˜ ì ìš©
        os.environ.update(common_env)
        
        # PyTorch ì„¤ì • (í”Œë«í¼ ê³µí†µ)
        torch.set_num_threads(1)
        torch.set_num_interop_threads(1)
        
        # í”Œë«í¼ë³„ PyTorch ë°±ì—”ë“œ ì„¤ì •
        if hasattr(torch.backends, 'openmp'):
            torch.backends.openmp.is_available = lambda: False
            
        # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
        print(f"ğŸ–¥ï¸  í”Œë«í¼: {current_platform.title()}" + 
              (f" (Apple Silicon)" if is_apple_silicon else ""))
        print(f"ğŸ”§ í™˜ê²½ ìµœì í™”: {'macOS' if is_macos else 'Windows' if is_windows else 'Linux'} ëª¨ë“œ")
        
    def force_cleanup(self):
        """ê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

# ========================================
# ì•ˆì „í•œ ëª¨ë¸ ê´€ë¦¬
# ========================================

@contextmanager
def safe_model_context(model_name, force_load=False):
    """ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ/ì–¸ë¡œë“œ ì»¨í…ìŠ¤íŠ¸"""
    model = None
    memory_manager = WhisperMemoryManager()
    
    try:
        # ì•ˆì •ì„± ì²´í¬
        if not force_load and model_name in RISKY_MODELS:
            print(f"âš ï¸ {model_name}ì€ í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            alt_model = suggest_safe_alternative(model_name)
            print(f"ğŸ’¡ ê¶Œì¥ ëŒ€ì•ˆ: {alt_model}")
            
            confirm = input(f"ê·¸ë˜ë„ {model_name}ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if confirm.lower() != 'y':
                print(f"ğŸ”„ {alt_model} ëª¨ë¸ë¡œ ë³€ê²½í•©ë‹ˆë‹¤")
                model_name = alt_model
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ë¡œë“œ
        memory_manager.force_cleanup()
        
        info = MODEL_INFO.get(model_name, {})
        print(f"ğŸ“¥ {model_name} ëª¨ë¸ ë¡œë“œ ì¤‘...")
        print(f"ğŸ“Š ì˜ˆìƒ í¬ê¸°: {info.get('memory', 'Unknown')}, ì •í™•ë„: {info.get('accuracy', 'Unknown')}")
        
        model = whisper.load_model(model_name)
        
        # ì‹¤ì‹œê°„ ìµœì í™” ì ìš©
        if hasattr(model, 'optimize_for_realtime'):
            model.optimize_for_realtime()
            
        print(f"âœ… {model_name} ë¡œë“œ ì„±ê³µ")
        
        yield model
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì—ëŸ¬ ìœ í˜•ë³„ ì²˜ë¦¬
        if "out of memory" in str(e).lower():
            print("ğŸ’¾ ë©”ëª¨ë¦¬ ë¶€ì¡± - ë” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        elif any(word in str(e).lower() for word in ["segmentation", "fault", "crash"]):
            print("ğŸ”§ Segmentation Fault - ì‹œìŠ¤í…œ ë¶ˆì•ˆì •")
            print("ğŸ’¡ í•´ê²°ì±…: ì‹œìŠ¤í…œ ì¬ì‹œì‘ ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©")
        else:
            print(f"ğŸ› ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {type(e).__name__}")
        
        raise
        
    finally:
        if model is not None:
            del model
        memory_manager.force_cleanup()
        print("ğŸ§¹ ëª¨ë¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

def suggest_safe_alternative(risky_model):
    """ìœ„í—˜í•œ ëª¨ë¸ì— ëŒ€í•œ ì•ˆì „í•œ ëŒ€ì•ˆ ì œì‹œ"""
    if risky_model.startswith('large'):
        return 'medium'  # ê°€ì¥ í° ì•ˆì „í•œ ëª¨ë¸
    return 'base'

# ========================================
# ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
# ========================================

def find_audio_file(audio_dir, audio_name):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ëŠ” í•¨ìˆ˜ (í™•ì¥ì ìë™ ê°ì§€)
    ê´„í˜¸ê°€ í¬í•¨ëœ í•œê¸€ íŒŒì¼ëª…ë„ ì²˜ë¦¬
    """
    extensions = ['mp3', 'wav', 'flac', 'm4a', 'ogg', 'mp4', 'aac']
    
    # 1. ì •í™•í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì‹œë„
    for ext in extensions:
        exact_path = os.path.join(audio_dir, f"{audio_name}.{ext}")
        if os.path.exists(exact_path):
            return exact_path
    
    # 2. glob íŒ¨í„´ìœ¼ë¡œ ìœ ì‚¬í•œ íŒŒì¼ ì°¾ê¸°
    for ext in extensions:
        pattern = os.path.join(audio_dir, f"*{audio_name}*.{ext}")
        try:
            matches = glob.glob(pattern)
            if matches:
                print(f"ğŸ’¡ ìœ ì‚¬í•œ íŒŒì¼ ë°œê²¬: {os.path.basename(matches[0])}")
                return matches[0]
        except:
            continue
    
    # 3. ë””ë ‰í† ë¦¬ ì „ì²´ ê²€ìƒ‰
    try:
        all_files = []
        for ext in extensions:
            pattern = os.path.join(audio_dir, f"*.{ext}")
            all_files.extend(glob.glob(pattern))
        
        # íŒŒì¼ëª…ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ íŒŒì¼ ì°¾ê¸°
        for file_path in all_files:
            filename = os.path.basename(file_path)
            if audio_name in filename:
                print(f"ğŸ’¡ ë¶€ë¶„ ì¼ì¹˜ íŒŒì¼ ë°œê²¬: {filename}")
                return file_path
                
    except Exception as e:
        print(f"âš ï¸ íŒŒì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return None

def load_audio_safe(file_path):
    """ì•ˆì „í•œ ì˜¤ë””ì˜¤ ë¡œë“œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
    
    # ë°©ë²• 1: librosa ì‚¬ìš©
    try:
        import librosa
        audio, sr = librosa.load(file_path, sr=16000, mono=True)
        print(f"âœ… librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ: {len(audio)/16000:.1f}ì´ˆ")
        return audio
    except ImportError:
        print("ğŸ“¦ librosa ë¯¸ì„¤ì¹˜ - ë‹¤ë¥¸ ë°©ë²• ì‹œë„")
    except Exception as e:
        print(f"âš ï¸ librosa ì‹¤íŒ¨: {e}")
    
    # ë°©ë²• 2: whisper ë‚´ì¥ ë°©ë²• ì‚¬ìš©
    try:
        from whisper.audio import load_audio
        audio = load_audio(file_path)
        print(f"âœ… whisper ë‚´ì¥ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ: {len(audio)/16000:.1f}ì´ˆ")
        return audio
    except Exception as e:
        print(f"âŒ whisper ë‚´ì¥ ë°©ë²•ë„ ì‹¤íŒ¨: {e}")
        raise

# ========================================
# ì•ˆì „í•œ ìŒì„± ì¸ì‹
# ========================================

def transcribe_safe(model, audio_data, language='ko', chunk_duration=30):
    """
    ì•ˆì „í•œ ìŒì„± ì¸ì‹ (Segfault ë°©ì§€ ê°•í™”)
    """
    try:
        # Segfault ë°©ì§€ë¥¼ ìœ„í•œ ì‚¬ì „ ì„¤ì •
        import torch
        torch.set_num_threads(1)  # ì¬í™•ì¸
        
        # ë©”ëª¨ë¦¬ ì‚¬ì „ ì •ë¦¬
        gc.collect()
        
        print("ğŸ”’ ì•ˆì „ ëª¨ë“œë¡œ ìŒì„± ì¸ì‹ ì‹œì‘...")
        
        # ê¸°ë³¸ ì²˜ë¦¬ ì‹œë„ (ìµœì†Œ ì˜µì…˜)
        result = whisper.transcribe(
            model,
            audio_data,
            language=language,
            fp16=False,              # Apple Silicon ì•ˆì •ì„±
            verbose=False,           # ì¶œë ¥ ìµœì†Œí™”
            beam_size=1,             # ë©”ëª¨ë¦¬ ì ˆì•½
            temperature=0,           # ê²°ì •ë¡ ì  ê²°ê³¼
            condition_on_previous_text=False,  # ë©”ëª¨ë¦¬ ì ˆì•½
            word_timestamps=False,    # íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„í™œì„±í™” (ì•ˆì •ì„±)
            no_speech_threshold=0.6,  # ë¬´ìŒ êµ¬ê°„ ì²˜ë¦¬
            logprob_threshold=-1.0,   # ë¡œê·¸ í™•ë¥  ì„ê³„ê°’
        )
        
        return result
        
    except Exception as e:
        print(f"âš ï¸ ê¸°ë³¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # ì²­í¬ ì²˜ë¦¬ë¡œ ì¬ì‹œë„
        return transcribe_chunked(model, audio_data, language, chunk_duration)

def transcribe_chunked(model, audio_data, language, chunk_duration=30):
    """ì²­í¬ ê¸°ë°˜ ì•ˆì „ ì²˜ë¦¬"""
    
    try:
        SAMPLE_RATE = 16000
        total_duration = len(audio_data) / SAMPLE_RATE
        
        print(f"ğŸ”„ ì²­í¬ ì²˜ë¦¬ ëª¨ë“œ ({chunk_duration}ì´ˆ ë‹¨ìœ„)")
        print(f"ğŸµ ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")
        
        if total_duration <= chunk_duration:
            # ì§§ì€ ì˜¤ë””ì˜¤ëŠ” í•œ ë²ˆì—
            result = whisper.transcribe(
                model, audio_data,
                language=language,
                fp16=False,
                verbose=False
            )
            return result
        
        # ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬
        chunk_size = chunk_duration * SAMPLE_RATE
        texts = []
        segments = []
        
        for i in range(0, len(audio_data), chunk_size):
            chunk_start_sec = i / SAMPLE_RATE
            chunk_audio = audio_data[i:i+chunk_size]
            
            print(f"   ğŸ“Š ì²˜ë¦¬ ì¤‘: {chunk_start_sec:.1f}ì´ˆ...")
            
            chunk_result = whisper.transcribe(
                model, chunk_audio,
                language=language,
                fp16=False,
                verbose=False,
                word_timestamps=True
            )
            
            texts.append(chunk_result['text'])
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì •
            if 'segments' in chunk_result:
                for segment in chunk_result['segments']:
                    segment['start'] += chunk_start_sec
                    segment['end'] += chunk_start_sec
                segments.extend(chunk_result['segments'])
            
            # ì²­í¬ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
        
        return {
            'text': ' '.join(texts),
            'language': language,
            'segments': segments
        }
        
    except Exception as e:
        print(f"âŒ ì²­í¬ ì²˜ë¦¬ë„ ì‹¤íŒ¨: {e}")
        raise

# ========================================
# ì‹ í˜¸ ì²˜ë¦¬
# ========================================

def signal_handler(signum, frame):
    """ì•ˆì „í•œ ì¢…ë£Œ ì²˜ë¦¬"""
    print(f"\n ì‹ í˜¸ {signum} ë°›ìŒ - ì•ˆì „í•˜ê²Œ ì¢…ë£Œ ì¤‘...")
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    sys.exit(0)

# ========================================
# ë©”ì¸ í•¨ìˆ˜
# ========================================

def main():
    # í¬ë¡œìŠ¤ í”Œë«í¼ ì‹ í˜¸ í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C (ëª¨ë“  í”Œë«í¼)
    
    # Windowsì—ì„œëŠ” SIGTERMì´ ì œí•œì ì´ë¯€ë¡œ ì¡°ê±´ë¶€ ë“±ë¡
    if platform.system().lower() != 'windows':
        signal.signal(signal.SIGTERM, signal_handler)  # Unix/Linux/macOSë§Œ
    
    # ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(
        description='Whisper STT ìµœì¢… í†µí•© ë²„ì „',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ (í¬ë¡œìŠ¤ í”Œë«í¼):
  # macOS/Linux
  python STT.py --model base --audio "íŒŒì¼ëª…" --language ko
  python STT.py --model tiny --audio "ë…¸ì´ì¦ˆì—†ëŠ”ë‹¨ì¼í™”ì(í•œì–´)2" --language ko --info
  
  # Windows  
  python STT.py --model base --audio "íŒŒì¼ëª…" --language ko
  python STT.py --model tiny --audio "ë…¸ì´ì¦ˆì—†ëŠ”ë‹¨ì¼í™”ì(í•œì–´)2" --language ko --info
  
  # ê³µí†µ
  python STT.py --list-models
        """
    )
    
    parser.add_argument('--model', type=str, default='base',
                       choices=list(MODEL_INFO.keys()),
                       help='ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: base)')
    parser.add_argument('--audio', type=str, required=True,
                       help='ì˜¤ë””ì˜¤ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)')
    parser.add_argument('--language', type=str, default='ko',
                       help='ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: ko)')
    parser.add_argument('--audio_dir', type=str, default='audio_data',
                       help='ì˜¤ë””ì˜¤ íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: audio_data)')
    parser.add_argument('--chunk_duration', type=int, default=30,
                       help='ì²­í¬ ê¸¸ì´(ì´ˆ) (ê¸°ë³¸: 30)')
    parser.add_argument('--force', action='store_true',
                       help='ìœ„í—˜í•œ ëª¨ë¸ë„ ê°•ì œ ì‚¬ìš©')
    parser.add_argument('--info', action='store_true',
                       help='ìƒì„¸ ì •ë³´ ì¶œë ¥')
    parser.add_argument('--list-models', action='store_true',
                       help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥')
    
    args = parser.parse_args()
    
    print("ğŸ¤ Whisper STT ìµœì¢… í†µí•© ë²„ì „")
    print("=" * 50)
    
    # ëª¨ë¸ ëª©ë¡ ì¶œë ¥
    if args.list_models:
        print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
        for model, info in MODEL_INFO.items():
            stability = "âœ… ì•ˆì „" if info['stable'] else "âš ï¸ ë¶ˆì•ˆì •"
            print(f"  {model:10s}: {info['memory']:>6s} | {info['accuracy']:>8s} | {stability}")
        return
    
    try:
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        print(f"ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ìƒ‰: {args.audio}")
        audio_file = find_audio_file(args.audio_dir, args.audio)
        
        if not audio_file:
            print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.audio}")
            print(f"ï¿½ ê²€ìƒ‰ ë””ë ‰í† ë¦¬: {os.path.abspath(args.audio_dir)}")
            print("ğŸ’¡ í•´ê²°ì±…:")
            print("  1. íŒŒì¼ëª… ì •í™•íˆ í™•ì¸")
            print("  2. ê´„í˜¸ í¬í•¨ ì‹œ ë”°ì˜´í‘œ ì‚¬ìš©")
            print(f'     python STT.py --model {args.model} --audio "{args.audio}"')
            return
        
        print(f"âœ… íŒŒì¼ ë°œê²¬: {os.path.basename(audio_file)}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(audio_file)/(1024*1024):.1f}MB")
        
        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        if args.info:
            info = MODEL_INFO[args.model]
            print(f"\nğŸ“‹ ëª¨ë¸ ì •ë³´:")
            print(f"  ğŸ·ï¸  ì´ë¦„: {args.model}")
            print(f"  ğŸ’¾ ë©”ëª¨ë¦¬: {info['memory']}")
            print(f"  ğŸ¯ ì •í™•ë„: {info['accuracy']}")
            print(f"  âš¡ ì†ë„: {info['speed']}")
            print(f"  ğŸ›¡ï¸  ì•ˆì •ì„±: {'ì•ˆì „' if info['stable'] else 'ë¶ˆì•ˆì •'}")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        print(f"\nğŸµ ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘...")
        audio_data = load_audio_safe(audio_file)
        
        # ëª¨ë¸ ë¡œë“œ ë° ìŒì„± ì¸ì‹
        with safe_model_context(args.model, args.force) as model:
            print(f"\nğŸ—£ï¸ ìŒì„± ì¸ì‹ ì‹œì‘ (ì–¸ì–´: {args.language})...")
            
            result = transcribe_safe(
                model, 
                audio_data, 
                args.language, 
                args.chunk_duration
            )
            
            # ê²°ê³¼ ì¶œë ¥
            print("\n" + "="*50)
            print("ğŸ‰ ìŒì„± ì¸ì‹ ì™„ë£Œ!")
            print(f"ğŸŒ ê°ì§€ ì–¸ì–´: {result.get('language', args.language)}")
            print(f"ğŸ“ ì¸ì‹ ê²°ê³¼:")
            print(f"   {result['text']}")
            
            # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´
            if args.info and 'segments' in result and result['segments']:
                print(f"\nâ±ï¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ (ì´ {len(result['segments'])}ê°œ):")
                for i, segment in enumerate(result['segments'][:5]):  # ì²˜ìŒ 5ê°œë§Œ
                    start, end = segment['start'], segment['end']
                    text = segment['text'].strip()
                    print(f"  {i+1:2d}. [{start:5.1f}s-{end:5.1f}s] {text}")
                if len(result['segments']) > 5:
                    print(f"     ... (ë‚˜ë¨¸ì§€ {len(result['segments'])-5}ê°œ)")
            
            print("="*50)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤")
        
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì—ëŸ¬: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. ëª¨ë¸ ëª©ë¡ í™•ì¸: --list-models")
        print("2. ë” ì‘ì€ ëª¨ë¸: --model tiny")
        print("3. ê°•ì œ ì‹¤í–‰: --force")
        print("4. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: pip install librosa")
        print("5. ì‹œìŠ¤í…œ ì¬ì‹œì‘")
        
        if args.info:
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()