#!/usr/bin/env python3
import whisper
import torch
import gc
import os
import argparse
import librosa
import time

import warnings
from contextlib import contextmanager, redirect_stdout, redirect_stderr


@contextmanager
def silent_io():
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        with open(os.devnull, "w") as devnull, \
             redirect_stdout(devnull), \
             redirect_stderr(devnull):
            yield

def find_audio_file(audio_dir, audio_name):
    extensions = ['mp3', 'wav', 'flac', 'm4a', 'ogg', 'mp4', 'aac']
    for ext in extensions:
        exact_path = os.path.join(audio_dir, f"{audio_name}.{ext}")
        if os.path.exists(exact_path):
            return exact_path
    return None

def main():
    parser = argparse.ArgumentParser(description='Whisper STT Only (No Translation)')
    parser.add_argument('--model', type=str, default='base', 
                        help='Whisper model (tiny/base/small/medium/large)')
    parser.add_argument('--audio', type=str, required=True, 
                        help='Audio file name (without extension)')
    parser.add_argument('--audio_dir', type=str, default='audio_data', 
                        help='Audio directory path')
    parser.add_argument('--verbose', action='store_true', 
                        help='Show detailed transcription info')
    args = parser.parse_args()

    model = None
    try:
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        audio_file = find_audio_file(args.audio_dir, args.audio)
        if not audio_file:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{args.audio}' (dir='{args.audio_dir}')")
            return

        print(f"ğŸ“ íŒŒì¼: {audio_file}")

        # 2. ì˜¤ë””ì˜¤ ë¡œë“œ
        print("ğŸ”Š ì˜¤ë””ì˜¤ ë¡œë”© ì¤‘...")
        with silent_io():
            audio_data = librosa.load(audio_file, sr=16000, mono=True)[0]
        
        duration = len(audio_data) / 16000
        print(f"â±ï¸  ê¸¸ì´: {duration:.2f}ì´ˆ")

        # 3. ëª¨ë¸ ë¡œë“œ
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘... (model={args.model}, device={device})")
        
        with silent_io():
            model = whisper.load_model(args.model, device=device)
        
        if device == "cuda":
            model.float()

        # 4. ìŒì„± ì¸ì‹ (STTë§Œ ìˆ˜í–‰)
        print("ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘...")
        with silent_io():
            result = model.transcribe(audio_data, fp16=False)
        
        # 5. ê²°ê³¼ ì¶œë ¥
        lang = result.get("language", "unknown")
        text = (result.get("text") or "").strip()
        
        print("\n" + "="*60)
        print(f"ğŸŒ ê°ì§€ ì–¸ì–´: {lang}")
        print("="*60)
        print(f"ğŸ“ ì „ì‚¬ ê²°ê³¼:\n{text}")
        print("="*60)
        
        # 6. ìƒì„¸ ì •ë³´ ì¶œë ¥ (ì˜µì…˜)
        if args.verbose and "segments" in result:
            print(f"\nğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ (ì´ {len(result['segments'])}ê°œ):")
            print("-"*60)
            for i, seg in enumerate(result['segments'], 1):
                start = seg.get('start', 0)
                end = seg.get('end', 0)
                seg_text = seg.get('text', '').strip()
                print(f"{i}. [{start:.2f}s ~ {end:.2f}s] {seg_text}")
            print("-"*60)

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if model is not None:
            del model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

if __name__ == "__main__":
    start_time = time.time()
    main()
    end_time = time.time()
    print(f"ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")