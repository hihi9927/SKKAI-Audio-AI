#!/usr/bin/env python3
import whisper
import torch
import gc
import os
import argparse
import librosa

import warnings
from contextlib import contextmanager, redirect_stdout, redirect_stderr

try:
    from googletrans import Translator  # ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ìš© (ì˜¨ë¼ì¸)
    _gt_available = True
except Exception:
    _gt_available = False

# ëª¨ë“  ì¶œë ¥/ê²½ê³ ë¥¼ ì ê·¸ëŠ” ì»¨í…ìŠ¤íŠ¸

@contextmanager
def silent_io():
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        with open(os.devnull, "w") as devnull, \
             redirect_stdout(devnull), \
             redirect_stderr(devnull):
            yield

def find_audio_file(audio_dir, audio_name):
    extensions = ['mp3', 'wav', 'flac', 'm4a', 'ogg', 'mp4', 'aac']
    for ext in extensions:
        exact_path = os.path.join(audio_dir, f"{audio_name}.{ext}")
        if os.path.exists(exact_path):
            return exact_path
    return None

def main():
    parser = argparse.ArgumentParser(description='Whisper STT Script')
    parser.add_argument('--model', type=str, default='base', help='Model to use')
    parser.add_argument('--audio', type=str, required=True, help='Audio file name')
    parser.add_argument('--audio_dir', type=str, default='audio_data', help='Audio directory')
    args = parser.parse_args()

    model = None
    try:
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        audio_file = find_audio_file(args.audio_dir, args.audio)
        if not audio_file:
            print(f"íŒŒì¼ì—†ìŒ: '{args.audio}' (dir='{args.audio_dir}')")
            return

        # 2. ì˜¤ë””ì˜¤ ë¡œë“œ
        with silent_io():
            audio_data = librosa.load(audio_file, sr=16000, mono=True)[0]        

        # 3. ëª¨ë¸ ë¡œë“œ
        device = "cuda" if torch.cuda.is_available() else "cpu"
        with silent_io():
            model = whisper.load_model(args.model, device=device)        

        # GPU ì‚¬ìš© ì‹œ ëª¨ë¸ì„ float32ë¡œ ë³€í™˜ (ì•ˆì •ì„± í™•ë³´)
        if device == "cuda":
            model.float()

        # 4. ìŒì„± ì¸ì‹
        with silent_io():
            result = model.transcribe(audio_data, language='ko', fp16=False)  # fp16=Falseë¡œ ì•ˆì •ì„± í™•ë³´
        
        # ğŸ”¹ ì–¸ì–´ ê°ì§€ ê²°ê³¼
        lang = result.get("language", "unknown")
        text = (result.get("text") or "").strip()

        if lang == "ko":
            kor_text = text
            # ì›ë¬¸ì´ í•œêµ­ì–´ë©´ ì˜ì–´ ë²ˆì—­ì€ whisper translateë¡œ
            with silent_io():
                translated_en = model.transcribe(audio_data, task="translate", fp16=False)
            eng_text = (translated_en.get("text") or "").strip()
        else:
            # ì›ë¬¸ì´ ì˜ì–´ë©´: ì˜ì–´ ì „ì‚¬ í™•ë³´
            if lang == "en":
                eng_text = text
            else:
                # ê·¸ ì™¸ ì–¸ì–´ë©´ ì˜ì–´ ë²ˆì—­ ë¨¼ì € í™•ë³´
                with silent_io():
                    to_en = model.transcribe(audio_data, task="translate", fp16=False)
                eng_text = (to_en.get("text") or "").strip()

            # ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ (googletrans ìˆìœ¼ë©´ ì‚¬ìš©)
            if _gt_available:
                try:
                    kor_text = Translator().translate(eng_text, src="en", dest="ko").text
                except Exception:
                    kor_text = "(í•œêµ­ì–´ ë²ˆì—­ ì‹¤íŒ¨)"
            else:
                kor_text = "(í•œêµ­ì–´ ë²ˆì—­ í•„ìš”: googletrans ë¯¸ì„¤ì¹˜)"

        # 5. ìµœì¢… ì¶œë ¥: ê°ì§€ì–¸ì–´ + í•œêµ­ì–´/ì˜ì–´ ìë§‰
        print(f"[ì–¸ì–´ ê°ì§€] {lang}")
        print(f"[í•œêµ­ì–´] {kor_text}")
        print(f"[ì˜ì–´] {eng_text}")


    except Exception as e:
        print(f"ì—ëŸ¬: {e}")

    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if model is not None:
            del model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

if __name__ == "__main__":
    main()