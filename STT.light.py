#!/usr/bin/env python3
import whisper
import torch
import gc
import os
import argparse
import librosa
import platform
from contextlib import contextmanager

def find_audio_file(audio_dir, audio_name):
    extensions = ['mp3', 'wav', 'flac', 'm4a', 'ogg', 'mp4', 'aac']
    for ext in extensions:
        exact_path = os.path.join(audio_dir, f"{audio_name}.{ext}")
        if os.path.exists(exact_path):
            return exact_path
    return None

def main():
    parser = argparse.ArgumentParser(description='Whisper STT Script')
    parser.add_argument('--model', type=str, default='base', help='Model to use')
    parser.add_argument('--audio', type=str, required=True, help='Audio file name')
    parser.add_argument('--audio_dir', type=str, default='audio_data', help='Audio directory')
    args = parser.parse_args()

    print("=" * 50)
    print("ğŸ¤ Whisper STT ì‹œì‘")
    print("=" * 50)

    model = None
    try:
        # 1. ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        print(f"ğŸ“ ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ìƒ‰: {args.audio}")
        audio_file = find_audio_file(args.audio_dir, args.audio)
        if not audio_file:
            print(f"âŒ '{args.audio}' íŒŒì¼ì„ '{args.audio_dir}' í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"âœ… íŒŒì¼ ë°œê²¬: {os.path.basename(audio_file)}")

        # 2. ì˜¤ë””ì˜¤ ë¡œë“œ
        print("\nğŸµ ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘...")
        audio_data = librosa.load(audio_file, sr=16000, mono=True)[0]
        print("âœ… ì˜¤ë””ì˜¤ ë¡œë“œ ì„±ê³µ")

        # 3. ëª¨ë¸ ë¡œë“œ
        print(f"\nğŸ“¥ '{args.model}' ëª¨ë¸ ë¡œë“œ ì¤‘...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = whisper.load_model(args.model, device=device)

        # GPU ì‚¬ìš© ì‹œ ëª¨ë¸ì„ float32ë¡œ ë³€í™˜ (ì•ˆì •ì„± í™•ë³´)
        if device == "cuda":
            model.float()
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")

        # 4. ìŒì„± ì¸ì‹
        print("\nğŸ—£ï¸ ìŒì„± ì¸ì‹ ì‹œì‘...")
        result = model.transcribe(audio_data, language='ko', fp16=False) # fp16=Falseë¡œ ì•ˆì •ì„± í™•ë³´

        # 5. ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*50)
        print("ğŸ‰ ìŒì„± ì¸ì‹ ì™„ë£Œ!")
        print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {result['text'].strip()}")
        print("="*50)

    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}")

    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if model is not None:
            del model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        print("\nğŸ§¹ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ.")

if __name__ == "__main__":
    main()